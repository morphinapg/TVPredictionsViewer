<?xml version="1.0" encoding="UTF-8"?>
<ContentView xmlns="http://xamarin.com/schemas/2014/forms" 
             xmlns:x="http://schemas.microsoft.com/winfx/2009/xaml"
             xmlns:d="http://xamarin.com/schemas/2014/forms/design"
             xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"
             mc:Ignorable="d"
             x:Class="TVPredictionsViewer.About">
  <ContentView.Content>
        <StackLayout Margin="15">
            <ScrollView>
                <Label LineBreakMode="WordWrap">
                    Hello there! My name is Andy Gilleand. Some of you may recognize my name if you’ve ever visited the comment section of TV by the Numbers, where I have posted my predictions for years. Some people may even recognize my name from a popular gaming YouTube channel I run. I have a lot of interests and hobbies, and one of those is TV. I watch a ton of TV. Chances are, I probably watch more new TV a week than most of you. I’m currently tracking over 80 shows throughout the year, most of them being currently running TV series, although I do have one or two older shows I watch at a time as well. 

On top of being a big fan of TV, I’m also a huge data nerd. Put both of these things together, and I’ve always been super interested in why certain shows are renewed and others are canceled. I always understood that “ratings” were a big part of it, but what are ratings exactly? They’re not reviews. They don’t measure how high quality a show is, how much people like or dislike a show. They’re also not exactly a general “how many people are watching this show” either. They specifically refer to a relative measure of the proportion of people in the 18-49-year age group that watched an episode of TV the same night it aired, between airtime and 3AM that night. This is called the Live + Same Day demographic rating.

Right now, they’re our best measure for determining whether a show will be renewed or not. That is because ultimately, TV is a business, and broadcast TV in particular’s business is all about selling TV ad space. The actual numbers TV networks use to sell this ad space are referred to as “commercial ratings”, commonly called C3 and C7. These numbers measure the actual number of minutes of ads that were watched within 3 and 7 days of TV watching. You might think, okay, so why don’t we use “DVR Ratings”, such as Live+3 or Live+7-day ratings, which sound like they might line up better with what the networks measure? Well, the fact is they don’t actually line up as well as you might think, and that’s because typically, when people watch a program on DVR, they likely aren’t watching commercials anywhere near as much as if they watched on the same night it aired. So, in actuality, the Live+SD ratings are the closest measure we have to the C3 and C7 ratings, which are not publicly available. 

I’ve been following TV ratings religiously for probably close to a decade now. When I first started paying attention, it seemed like a good rule of thumb that if a show was above a 2.0 rating (representing 2% of the demographic watching that program) it was likely to be renewed, if it was below a 1.0 is was almost certainly being canceled, and in between it was a little harder to guess. Over time though, that rule of thumb quickly went away as TV ratings declined, due to streaming services and on demand platforms. So, it doesn’t make any sense to look at the exact ratings as an estimate for whether a show will be renewed or not. 

I quickly noticed on TV by the Numbers’ “Cancellation Bear”, that they were measuring things in a relative sense, essentially. How much higher or lower than the average rating for the network is a show rating? That seemed like a pretty good measure, as that would remain something you could do every year. One year however, TVBTN changed their “Bear” author, and they changed their methodology to something a bit more simple, and I was not as happy with their results. So, I started playing around with Excel trying to recreate what I had seen in earlier years. 

It turns out, while the basic idea of comparing average ratings of each show to the average rating of the network was much more useful than simply looking at the raw numbers, there was something that was still preventing my predictions from being very accurate. First of all, I stopped doing straight averages. Instead I weighted the ratings towards the later episodes in the season, since how a show is performing near the end of the season is more relevant to renewal. This was particularly helpful after a show like 24: Legacy premiered after the Superbowl and significantly threw off predictions but doing this alone wasn’t enough. So, I asked myself if I could come up with something better. This led to an idea I refer to as “Renewal Index”. 

To understand Renewal Index, you must think of TV in a business/money sense. Imagine each show’s rating represents a monetary value, per half hour. If we add up all ratings, with hour long shows being weighed twice as much as half hour-long shows, we get a number representative of the “total income” for the network. The idea behind Renewal Index is that if you pile these shows’ values from lowest to highest, there is a certain point in the stack where all of the shows above that line make enough money to fund the network’s budget for the year. Above that line, those shows are expected to be renewed, and below that line, those shows are expected to be canceled.

I used statistical analysis, measuring what the most likely Renewal Index was for each network, based on renewals and cancellations from the 2015-2016 TV season, and this ended up significantly improving my prediction accuracy, but it wasn’t enough. Throughout the year while posting my predictions in the comments, I frequently had people letting me know that ratings, while a big indicator for renewal, aren’t everything. There are other factors, such as network ownership, syndication, and timeslot, amongst others. So, the next year, I decided to add those factors to my equation.

I used the same process that I used to determine overall network Renewal Index in order to find indexes for each factor, and then found an equation that would translate the network Renewal Index to the factor renewal index, using exponents to keep it in the 0-100 space. Each additional factor I tracked would compound further on the original index, giving each show a unique renewal index. To determine odds, I used the LOG of the show’s actual index / the LOG of the show’s renewal index. This gave me a percentage between 0-100%, with 50% representing a show that is directly on top of the renewal index. The highest rated show on a network would get 100% odds, and the lowest rated show would get 0% odds. I translated these from odds percentages to a percentage confidence in renewal or cancellation. So, if a show has 50% odds, then you have to be 0% confident it will be renewed or canceled. 

This significantly improved my predictions again, but I still wasn’t totally happy with my results. One thing that annoyed me was that the highest and lowest rated shows were always exactly 100% confidence in renewal or cancellation, regardless of closeness to renewal threshold or accuracy of predictions. So, I changed the index calculation to an “exclusive” percentile like calculation, meaning nothing gets 0% or 100% indexes exactly. This leaves them close to the extremes, but still manipulatable by the factors. I also calculated how accurate the prediction model for each network was and applied that to the confidence percentage as well. This led to the top and bottom rated shows being able to potentially shift if the factors were considerable enough, and also allowed the confidence percentages to be a bit more reflective of reality. 

Then I got another idea. At this time, I was working as a math tutor at a college, focusing on tutoring Excel (everybody called me the Excel Guru). During this time, I actually ended up learning new techniques as I was helping the students. One of those techniques was using something called the “Solver” plugin, to calculate optimal values in an equation, and this could also use evolutionary techniques for solving this problem as well. This was perfect! While I believed my index and factor equation was rather well designed from the start, I always worried that adding more factors could potentially add too much of a contribution from the factors, ultimately reducing accuracy. So instead of me calculating thresholds manually, I would now allow Solver to calculate what all the thresholds should be, and I significantly improved my accuracy once again.

And this is where I was at the beginning of the 2018-2019 TV season. My predictions were fairly accurate, and there was a decent level of computer AI that went into ensuring that. But then later in that season, I had another idea! I’ve always been a programmer, and over the years I’ve become a bit interested in the idea of “deep learning”, or computer programs that learn the solution to problems through something called “neural networks”. A complex web of calculations, that ultimately not only finds the optimal combination of factors, but actually end up figuring out what kind of math/equation to even use in the first place. As good as finding an optimal solution was in Excel, it still relied on the assumption that my base equation was well designed. Neural networks don’t need to know what kind of math to use. They figure that out on their own. So, I decided to write an app to process the results of my statistical collection over the years, using a neural network. And my accuracy increased significantly more. As of writing this, my neural network is able to predict 100/101 shows from the 2018-2019 TV season correctly, with a total accuracy of 521/540 shows from 2014-2019, for an average 96% accuracy. 

I weigh the neural network “error minimizing” calculation by newer seasons being more important, and by shows that are closer to the network’s average renewal threshold being more important as well (since the shows at the extremes are easier to predict). This significantly helps in improving accuracy of newer shows. I’ve also added the ability to predict what a show’s final weighted average rating would be, by comparing the statistics about how ratings typically drop off on each network. This helps achieve a more level playing field in ranking the shows, and since ranking significantly impacts the show’s rating index, and shows premiere all at different parts of the year, it was important that I could put them in as level playing ground as possible. So, the number you see in this app for “Season Rating” is actually the projected final rating the show will likely have at the end of the season. There’s even a page where you can see what ratings we should expect for the show to reach that average. 

Because this is now a neural network, the calculation for how odds are arrived at is more complicated. I can’t simply say that airing on a Friday will always give you a certain % boost in probability of renewal. Neural networks are SMART. They can recognize patterns that no human ever would. Perhaps airing on Friday isn’t as important if a show is already syndicated. Perhaps network ownership of a show matters less if the show airs in Summer, etc. Basically, each factor can react differently to each different unique set of factors, resulting in renewal thresholds I never would have been able to come up with using the old methods, and the reason these models are likely to be more accurate than just about anybody else doing anything similar. 

That being said, they are data-driven models, and the more data we have available for currently airing shows, the better the predictions will be. As more shows premiere throughout the season, this can dramatically impact the rankings of shows, and therefore impact predictions as well. While I designed the Renewal Index and Weighted Average Rating system to be able to work well at any point of the year, it can only make its best guesses about the state of the network at the end of the season. I think it does a good job, but it will always be at its best later in the season, once more shows have premiered.

I have two apps. I have this app you’re using right now, which displays the predictions, and I also have an app only I use, which is used to actually perform the learning/training process of the neural network. I leave this app using the full power of my CPU (a fairly beefy one as of 2019) 24 hours a day all week (unless I need the CPU power for something else like encoding videos for my YouTube channel). I then export images of each chart from that app, write a post about what’s changed in the last week, and post it to my Facebook Page (link below). As soon as that gets posted to the Facebook page, this app will be able to download the new predictions, and display them in an interactive, customizable, user friendly format. 

If you’ve made it this far, thank you for reading this, and I hope you enjoy using my app! Be sure to give the app a review so I know what people think about it. You can also comment on my most recent predictions by vising the Facebook Page below.
                </Label>
            </ScrollView>
            <Grid MinimumHeightRequest="50">
                <Grid.ColumnDefinitions>
                    <ColumnDefinition Width="*"/>
                    <ColumnDefinition Width="15*"/>
                    <ColumnDefinition Width="*"/>
                </Grid.ColumnDefinitions>

                <Grid.RowDefinitions>
                    <RowDefinition Height="*"/>
                    <RowDefinition Height="3*"/>
                    <RowDefinition Height="*"/>
                </Grid.RowDefinitions>

                <ImageButton Source="facebook.png" Grid.Column="1" Grid.Row="1" CornerRadius="15" Clicked="ImageButton_Clicked" BackgroundColor="{DynamicResource DetailBackground}" />
            </Grid>
        </StackLayout>
    </ContentView.Content>
</ContentView>